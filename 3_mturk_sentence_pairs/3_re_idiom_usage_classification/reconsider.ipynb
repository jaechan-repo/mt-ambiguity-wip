{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "df = pd.read_csv(\"instances_retrial_2.csv\")\n",
    "df = df.rename(\n",
    "    columns={\n",
    "        'intended_ambiguous': 'intended_ambiguous_old',\n",
    "        'intended_figurative': 'intended_figurative_old',\n",
    "        'intended_literal': 'intended_literal_old',\n",
    "        'intended_ambiguous_retrial': 'intended_ambiguous', \n",
    "        'intended_figurative_retrial': 'intended_figurative',\n",
    "        'intended_literal_retrial': 'intended_literal',\n",
    "    })\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHES = ['she', 'her', 'hers', 'herself']\n",
    "HES = ['he', 'his', 'him', 'himself']\n",
    "THEYS = ['they', 'their', 'them', 'theirs', 'themselves']\n",
    "SHES_TO_HES = {\n",
    "    ('she', '*') : ('he', '*'),\n",
    "    ('her', 'poss') : ('his', 'poss'),\n",
    "    ('her', 'dobj') : ('him', 'dobj'),\n",
    "    ('her', 'pobj') : ('him', 'pobj'),\n",
    "    ('hers', '*') : ('his', 'attr'),\n",
    "    ('herself', '*') : ('himself', '*')\n",
    "}\n",
    "HES_TO_SHES = {v: k for k, v in SHES_TO_HES.items()}\n",
    "HES_TO_THEYS = {\n",
    "    ('he', '*') : ('they', '*'),\n",
    "    ('his', 'poss'): ('their', '*'),\n",
    "    ('him', 'dobj') : ('them', 'dobj'),\n",
    "    ('him', 'pobj') : ('them', 'pobj'),\n",
    "    ('his', 'attr') : ('theirs', '*'),\n",
    "    ('himself', '*') : ('themselves', '*')\n",
    "}\n",
    "SHES_TO_THEYS = {HES_TO_SHES[k]: v for k, v in HES_TO_THEYS.items()}\n",
    "\n",
    "def f(row):\n",
    "    row['intended_ambiguous'] = row['intended_ambiguous'].replace(\"<\", \"\").replace(\">\", \"\")\n",
    "    row['intended_figurative'] = row['intended_figurative'].replace(\"<\", \"\").replace(\">\", \"\")\n",
    "    row['intended_literal'] = row['intended_literal'].replace(\"<\", \"\").replace(\">\", \"\")\n",
    "\n",
    "    converted = pronoun_conversion(\n",
    "        row['intended_ambiguous'], \n",
    "        row['intended_figurative'], \n",
    "        row['intended_literal']\n",
    "    )\n",
    "    row['converted'] = False\n",
    "    if converted is not None:\n",
    "        row[['intended_ambiguous', 'intended_figurative', 'intended_literal']] = converted\n",
    "        row['converted'] = True\n",
    "    return row\n",
    "    \n",
    "def pronoun_conversion(ss_ambiguous, s_figurative, s_literal):\n",
    "\n",
    "    ss_ambiguous_doc = nlp(ss_ambiguous)\n",
    "    s_figurative_doc = nlp(s_figurative)\n",
    "    s_literal_doc = nlp(s_literal)\n",
    "\n",
    "    if ss_ambiguous_doc[0].pos_ != 'VERB':\n",
    "        return None\n",
    "\n",
    "    idx_fig = -1\n",
    "    for i in range(len(s_figurative_doc) - len(ss_ambiguous_doc) + 1):\n",
    "        substring = s_figurative_doc[i : i + len(ss_ambiguous_doc)]\n",
    "        if substring.text == ss_ambiguous_doc.text:\n",
    "            idx_fig = i\n",
    "            break\n",
    "\n",
    "    if idx_fig in [-1, 0]: return None\n",
    "\n",
    "    idx_lit = -1\n",
    "    for i in range(len(s_literal_doc) - len(ss_ambiguous_doc) + 1):\n",
    "        substring = s_literal_doc[i : i + len(ss_ambiguous_doc)]\n",
    "        if substring.text == ss_ambiguous_doc.text:\n",
    "            idx_lit = i\n",
    "            break\n",
    "        \n",
    "    if idx_lit in {-1, 0}: return None\n",
    "\n",
    "    subj_fig = s_figurative_doc[idx_fig - 1]\n",
    "    subj_lit = s_literal_doc[idx_lit - 1]\n",
    "    \n",
    "    if {subj_fig.text, subj_lit.text} == {'she', 'he'}:\n",
    "\n",
    "        new_s_figurative = convert(s_figurative_doc, SHES_TO_HES, HES_TO_SHES, SHES, HES)\n",
    "        if new_s_figurative is not None \\\n",
    "                and f\"{subj_lit.text} {ss_ambiguous}\" in new_s_figurative:\n",
    "            return (f\"{subj_lit.text} {ss_ambiguous}\", new_s_figurative, s_literal)\n",
    "        \n",
    "        new_s_literal = convert(s_literal_doc, SHES_TO_HES, HES_TO_SHES, SHES, HES)\n",
    "        if new_s_literal is not None \\\n",
    "                and f\"{subj_fig.text} {ss_ambiguous}\" in new_s_literal:\n",
    "            return (f\"{subj_fig.text} {ss_ambiguous}\", s_figurative, new_s_literal)\n",
    "        \n",
    "    elif subj_fig.text == 'they' and not contains_they(s_literal_doc):\n",
    "        new_s_literal = None\n",
    "        if subj_lit.text == 'she':\n",
    "            new_s_literal = convert(s_literal_doc, SHES_TO_THEYS, {}, SHES, [])\n",
    "        elif subj_lit.text == 'he':\n",
    "            new_s_literal = convert(s_literal_doc, HES_TO_THEYS, {}, HES, [])\n",
    "\n",
    "        if new_s_literal is not None \\\n",
    "                and f\"they {ss_ambiguous}\" in new_s_literal:\n",
    "            return (f\"they {ss_ambiguous}\", s_figurative, new_s_literal)\n",
    "    \n",
    "    elif subj_lit.text == 'they' and not contains_they(s_figurative_doc):\n",
    "        new_s_figurative = None\n",
    "        if subj_fig.text == 'she':\n",
    "            new_s_figurative = convert(s_figurative_doc, SHES_TO_THEYS, {}, SHES, [])\n",
    "        elif subj_fig.text == 'he':\n",
    "            new_s_figurative = convert(s_figurative_doc, HES_TO_THEYS, {}, HES, [])\n",
    "\n",
    "        if new_s_figurative is not None \\\n",
    "                and f\"they {ss_ambiguous}\" in new_s_figurative:\n",
    "            return (f\"they {ss_ambiguous}\", new_s_figurative, s_literal)\n",
    "        \n",
    "    return None\n",
    "\n",
    "def contains_they(doc):\n",
    "    for token in doc:\n",
    "        for they in THEYS:\n",
    "            if token.text == they:\n",
    "                return True\n",
    "    return False\n",
    "    \n",
    "\n",
    "def convert(doc, dict1, dict2, list1, list2):\n",
    "    words = []\n",
    "    for token in doc:\n",
    "        token_tuple = (token.text, token.dep_)\n",
    "        token_wild = (token.text, '*')\n",
    "        if token_tuple in dict1:\n",
    "            words.append(dict1[token_tuple][0])\n",
    "        elif token_wild in dict1: \n",
    "            words.append(dict1[token_wild][0])\n",
    "        elif token_tuple in dict2:\n",
    "            words.append(dict2[token_tuple][0])\n",
    "        elif token_wild in dict2: \n",
    "            words.append(dict2[token_wild][0])\n",
    "        elif token.text in list1 or token.text in list2:\n",
    "            return None\n",
    "        else:\n",
    "            words.append(token.text)\n",
    "    return re.sub(r'\\s([?.!,\"\\'](?:\\s|$))', r'\\1', ' '.join(words))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 731/731 [00:07<00:00, 99.42it/s] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "df = df.progress_apply(f, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('instances_chatgpt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'attr'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[-1].dep_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(type(doc) == spacy.tokens.doc.Doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She\n",
      "looks\n",
      "at\n"
     ]
    }
   ],
   "source": [
    "for token in doc[0:3]:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
