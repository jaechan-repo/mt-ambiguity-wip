{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/92/6j34w0196yq0cnnrfrw0s68w0000gn/T/ipykernel_4247/1875973638.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('Input.', '')\n",
      "/var/folders/92/6j34w0196yq0cnnrfrw0s68w0000gn/T/ipykernel_4247/1875973638.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('Answer.', '')\n",
      "/var/folders/92/6j34w0196yq0cnnrfrw0s68w0000gn/T/ipykernel_4247/1875973638.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('Input.', '')\n",
      "/var/folders/92/6j34w0196yq0cnnrfrw0s68w0000gn/T/ipykernel_4247/1875973638.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('Answer.', '')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "batch1 = pd.read_csv(\"batch_1_50rows_HIT.csv\")\n",
    "\n",
    "def str_replace(df):\n",
    "    df.columns = df.columns.str.replace('Input.', '') \n",
    "    df.columns = df.columns.str.replace('Answer.', '')\n",
    "\n",
    "cols = ['idiom_0',\n",
    "       'instance_0', 'label_0', 'meaning_0', 'idiom_1', 'instance_1',\n",
    "       'label_1', 'meaning_1', 'idiom_2', 'instance_2', 'label_2', 'meaning_2',\n",
    "       'idiom_3', 'instance_3', 'label_3', 'meaning_3', 'idiom_4',\n",
    "       'instance_4', 'label_4', 'meaning_4', '0_gold', '0_revision', '1_gold',\n",
    "       '1_revision', '2_gold', '2_revision', '3_gold', '3_revision', '4_gold',\n",
    "       '4_revision', 'TimeMe', 'AssignmentId', 'WorkerId']\n",
    "\n",
    "column_groups = [\n",
    "        ['idiom_0', 'instance_0', 'label_0', 'meaning_0', '0_gold', '0_revision'],\n",
    "        ['idiom_1', 'instance_1', 'label_1', 'meaning_1', '1_gold', '1_revision'],\n",
    "        ['idiom_2', 'instance_2', 'label_2', 'meaning_2', '2_gold', '2_revision'],\n",
    "        ['idiom_3', 'instance_3', 'label_3', 'meaning_3', '3_gold', '3_revision'],\n",
    "        ['idiom_4', 'instance_4', 'label_4', 'meaning_4', '4_gold', '4_revision'],\n",
    "    ]\n",
    "\n",
    "# common columns for all rows\n",
    "common_cols = ['TimeMe', 'AssignmentId', 'WorkerId']\n",
    "batch1_result = pd.read_csv(\"batch_1_result.csv\")\n",
    "batch1_correction = pd.read_csv(\"batch_1_correction.csv\")\n",
    "str_replace(batch1_result)\n",
    "str_replace(batch1_correction)\n",
    "batch1_result = batch1_result[cols].fillna('{}')\n",
    "batch1_correction = batch1_correction[cols].fillna('{}Ã¥')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anyna(df):  \n",
    "    return df[df.isna().any(axis=1)].loc[:, df.isna().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melt_it(df):\n",
    "    # list of column sets\n",
    "\n",
    "    # melt the dataframe\n",
    "    dfs = []\n",
    "    for i, column_group in enumerate(column_groups):\n",
    "        melted = df[column_group + common_cols].copy()  # select the columns\n",
    "        melted.columns = ['idiom', 'instance', 'label', 'meaning', 'gold', 'revision'] + common_cols  # rename the columns\n",
    "        melted['group'] = i  # add a column to indicate the original group\n",
    "        dfs.append(melted)\n",
    "\n",
    "    # concatenate the melted dataframes\n",
    "    df_melted = pd.concat(dfs, ignore_index=True)\n",
    "    return df_melted.drop('group', axis=1)\n",
    "\n",
    "batch1_result = melt_it(batch1_result)\n",
    "batch1_correction = melt_it(batch1_correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = batch1_result.groupby(['idiom', 'instance', 'label', 'meaning']).agg(list).reset_index()\n",
    "df2 = batch1_correction.groupby(['idiom', 'instance', 'label', 'meaning']).agg(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate df1 and df2\n",
    "df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Drop duplicates based on 'idiom', 'instance', 'label', and 'meaning', keep the last occurrence (df2 entries)\n",
    "df = df.drop_duplicates(subset=['idiom', 'instance', 'label', 'meaning'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch1.columns = batch1.columns.str.replace('_', '')\n",
    "\n",
    "# create an id column to keep track of original rows\n",
    "batch1['id'] = np.arange(len(batch1))\n",
    "\n",
    "# reshape with wide_to_long\n",
    "batch1_melted = pd.wide_to_long(batch1.reset_index(), \n",
    "                             stubnames=['idiom', 'instance', 'label', 'meaning'], \n",
    "                             i=['index', 'id'], \n",
    "                             j='variable', \n",
    "                             sep='').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = batch1_melted.merge(\n",
    "    df, on=['idiom', 'instance', 'label', 'meaning'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def most_frequent(array):\n",
    "    count = Counter(array)\n",
    "    max_count = max(count.values())\n",
    "    max_elements = [k for k, v in count.items() if v == max_count]\n",
    "\n",
    "    if len(max_elements) > 1:\n",
    "        return 'tie'  # return -1 in case of a tie\n",
    "\n",
    "    return max_elements[0]  # return the most frequent element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['len'] = merged_df['gold'].apply(len)\n",
    "NUM_ASSIGNMENTS = 4\n",
    "labels = ['figurative', 'literal', 'ambiguous', 'discard']\n",
    "def f(row):\n",
    "    for i in range(NUM_ASSIGNMENTS):\n",
    "        row[f'gold_{i}'] = labels[row['gold'][i]]\n",
    "        row[f'revision_{i}'] = row['revision'][i]\n",
    "    row['label'] = labels[row['label']]\n",
    "    if row['len'] > NUM_ASSIGNMENTS:\n",
    "        row['gold'] = row['gold'][:4]\n",
    "        row['revision'] = row['revision'][:4]\n",
    "        row['TimeMe'] = row['TimeMe'][:4]\n",
    "        row['AssignmentId'] = row['AssignmentId'][:4]\n",
    "        row['WorkerId'] = row['WorkerId'][:4]\n",
    "    row['maxVote'] = most_frequent([\n",
    "        row[f'gold_{i}'] for i in range(NUM_ASSIGNMENTS)])\n",
    "    return row\n",
    "final = merged_df.apply(f, axis=1).drop('len', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "golds = final[[f'gold_{i}' for i in range(NUM_ASSIGNMENTS)]].copy()\n",
    "def g(row):\n",
    "    for i in range(NUM_ASSIGNMENTS):\n",
    "        row[f'gold_{i}'] = labels.index(row[f'gold_{i}'])\n",
    "    return row\n",
    "golds = golds.apply(g, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv(\"batch_1_agg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.inter_rater import aggregate_raters\n",
    "from statsmodels.stats.inter_rater import fleiss_kappa\n",
    "golds = aggregate_raters(golds)[0]\n",
    "kappa = fleiss_kappa(golds, method='fleiss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6258000395155159"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
